{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit"
  },
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Model inference on local device \n",
    "\n",
    "*prerequisites: model trained, compiled with neo, and stored on S3 && AWS CLI logged in* \n",
    "        \n",
    "這裡是示範如何在本地端透過從 S3 下載用 **Neo** compile 過的模型並用此模型做出 inference\n",
    "\n",
    "下面我們會一步一步的講解\n",
    "\n",
    "我測試使用的環境由於當初 Neo compile 時指定的裝置是 Raspberry Pi 4 B，所以這邊我是用 Rpi 4B, ubuntu 的環境\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "把 boto3 這個 AWS SDK import 進來，它的功能主要是能在 python 上使用 AWS 的資源\n",
    "\n",
    "注意這裡 AWS CLI 要已經在本地登入過\n",
    "\n",
    "**如果執行 import boto3 時遇到 No module named boto3, 執行下面的 cell** "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!pip install boto3"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "import boto3\n",
    "\n",
    "session = boto3.Session(profile_name='Ming') \n",
    "s3 = session.resource('s3')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "這裡簡單測試在 python 下面跑 AWS services, 成功的話所有 S3 bucket 會 print 出來"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "# Print out bucket names \n",
    "for bucket in s3.buckets.all():\n",
    "    print(bucket.name)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "cdktoolkit-stagingbucket-f3zt96glmy50\n",
      "cdktoolkit-stagingbucket-gdssexlww1z7\n",
      "fleetprovisiondemo-myvaulte4d40284-1820bzai96axd\n",
      "fleetprovisiondemo-myvaulte4d40284-ozh0yosvxtzc\n",
      "greenideas-lems-historybucket-oh28amet1tu8\n",
      "jitpdemo-myvaulte4d40284-jiikha5kz43t\n",
      "jitrdemo-myvaulte4d40284-1uabe8yjoasse\n",
      "sagemaker-neo-compile-test-20210723\n",
      "sagemaker-neo-compile-test-20210723-2\n",
      "sagemaker-studio-079794712254-uu5lhmaozq\n",
      "schedule-stack-demo-acerdemoeventbucketb52b79c6-19of1dp23erdy\n",
      "smart-space-demo-containerbucket9a65fa96-128ktchgr1cte\n",
      "smart-space-demo-containerbucket9a65fa96-n6249qapp1nl\n",
      "softchef-lab-hardware\n",
      "softchef-lab-recipe-images-demo\n",
      "test-testvaultb2fa1968-14neqavltvetn\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "下載 neo-compile 過的 model\n",
    "\n",
    "bucket 指定該 model 存放的 bucket, object_path 是 neo-compile 過的 model 在 bucket 下面的路徑， 最後一個變數是下載下來的名稱"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "s3client = session.client('s3')\n",
    "# Download compiled model locally to edge device\n",
    "bucket='sagemaker-neo-compile-test-20210723' # specify the bucket where the neo-compiled model stored\n",
    "object_path = 'xgboost-as-a-built-in-algo/output/sagemaker-xgboost-2021-07-23-neo-compiled-rasp4b/model-rasp4b.tar.gz' # specify the path of the model in the bucket\n",
    "neo_compiled_model = 'compiled-rasp4b.tar.gz' # download as this name \n",
    "s3client.download_file(bucket, object_path, neo_compiled_model)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "建立資料夾放 model, 解壓縮在裡面"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "!mkdir ./dlr_model # make a directory to store your model (optional)\n",
    "!tar -xzvf ./compiled-rasp4b.tar.gz --directory ./dlr_model "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "libdlr.so\n",
      "dlr.h\n",
      "compiled_model.so\n",
      "compiled.meta\n",
      "manifest\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "下面的 cell 執行前，要先在本地安裝 dlr, 如果是要在 x86_64 的 CPU 上面跑，可以直接執行"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!pip install dlr"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "如果要用 GPU 跑或是非 x86 的 ISA 上， 請[參閱](https://neo-ai-dlr.readthedocs.io/en/latest/install.html#)\n",
    "\n",
    "Raspberry Pi 4 B 的話可以直接執行下面"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!pip install https://neo-ai-dlr-release.s3-us-west-2.amazonaws.com/v1.9.0/rasp4b/dlr-1.9.0-py3-none-any.whl"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "import dlr\n",
    "\n",
    "device = 'cpu'\n",
    "model = dlr.DLRModel('./dlr_model', device) "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-07-26 15:15:14,106 INFO Found libdlr.so in model artifact. Using dlr from ./dlr_model/libdlr.so\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      " CALL HOME FEATURE ENABLED\n",
      "                            \n",
      "\n",
      " You acknowledge and agree that DLR collects the following metrics to help improve its performance.                             \n",
      " By default, Amazon will collect and store the following information from your device:                             \n",
      "\n",
      " record_type: <enum, internal record status, such as model_loaded, model_>,                             \n",
      " arch: <string, platform architecture, eg 64bit>,                             \n",
      " osname: <string, platform os name, eg. Linux>,                             \n",
      " uuid: <string, one-way non-identifable hashed mac address, eg. 8fb35b79f7c7aa2f86afbcb231b1ba6e>,                             \n",
      " dist: <string, distribution of os, eg. Ubuntu 16.04 xenial>,                             \n",
      " machine: <string, retuns the machine type, eg. x86_64 or i386>,                             \n",
      " model: <string, one-way non-identifable hashed model name, eg. 36f613e00f707dbe53a64b1d9625ae7d>                             \n",
      "\n",
      " If you wish to opt-out of this data collection feature, please follow the steps below:                             \n",
      "\t1. Disable it with through code:                             \n",
      "\t\t from dlr.counter.phone_home import PhoneHome                             \n",
      "\t\t PhoneHome.disable_feature()                            \n",
      "\t2. Or, create a config file, ccm_config.json inside your DLR target directory path, i.e. python3.6/site-packages/dlr/counter/ccm_config.json. Then added below format content in it, {\"enable_phone_home\" : false}                             \n",
      "\t3. Restart DLR application.                             \n",
      "\t4. Validate this feature is disabled by verifying this notification is no longer displayed, or programmatically with following command:                             \n",
      "\t\tfrom dlr.counter.phone_home import PhoneHome                             \n",
      "\t\tPhoneHome.is_enabled() # false as disabled \n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "有了 dlr (Deep Learning Runtime) 我們才能在本地跑 Neo-compiled model\n",
    "\n",
    "路徑指定之前解壓縮 model 的路徑\n",
    "\n",
    "這步結束後其實就能用 \n",
    "\n",
    "    out = model.run(x)\n",
    "\n",
    "的 code 跑 inference 了，其中 out 為模型輸出結果， x 是輸入的資料\n",
    "\n",
    "要注意當初 Neo-compile 時有指定 Data input configuration\n",
    "\n",
    "所以這邊使用時也要注意輸入資料的 shape \n",
    "\n",
    "這個範例當初 Data input configuration 是 {\"data\":[1, 59]}， 因此輸入的資料形狀要為二維且建議 shape 符合 (num, 59), 這邊 num 為要做 inference 的 data 數量 59 為輸入 feature 數量\n",
    "\n",
    "輸入 data 的 feature 數量若小於訓練時給的數量 (在這裡為59) 經測試其實 model 還是能做 inference， 但是不建議因為正確率會下降\n",
    " "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "下面就來測試在本地跑一樣的資料是否跟在 SageMaker 上產生的結果一樣\n",
    "\n",
    "來測試模型是否有正確作用\n",
    "\n",
    "這裡先下載並讀取之前在 SageMaker 上測試的資料"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "import pandas as pd\n",
    "import urllib\n",
    "try:\n",
    "    urllib.request.urlretrieve (\"https://d1.awsstatic.com/tmt/build-train-deploy-machine-learning-model-sagemaker/bank_clean.27f01fbbdf43271788427f3682996ae29ceca05d.csv\", \"bank_clean.csv\")\n",
    "    print('Success: downloaded bank_clean.csv.')\n",
    "except Exception as e:\n",
    "    print('Data load error: ',e)\n",
    "\n",
    "try:\n",
    "    model_data = pd.read_csv('./bank_clean.csv',index_col=0)\n",
    "    print('Success: Data loaded into dataframe.')\n",
    "except Exception as e:\n",
    "    print('Data load error: ',e)\n",
    "\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Success: downloaded bank_clean.csv.\n",
      "Success: Data loaded into dataframe.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "照著之前的方法切出測試資料"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "### Train Test split\n",
    "\n",
    "import numpy as np\n",
    "train_data, test_data = np.split(model_data.sample(frac=1, random_state=1729), [int(0.7 * len(model_data))])\n",
    "print(train_data.shape, test_data.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(28831, 61) (12357, 61)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "把測試資料除了 feature 的 column 移除"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "test_data_array = test_data.drop(['y_no', 'y_yes'], axis=1).values #load the data into an array"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "看一下測試資料的 shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "test_data_array.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(12357, 59)"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "這邊我們先測試只用一個 data 去做 inference\n",
    "\n",
    "取測試資料中的第一個"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "single_inference_data = test_data_array[0]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "確認 shape \n",
    "\n",
    "這個 shape 不能輸入模型"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "single_inference_data.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(59,)"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "用 NumPy 中的 expand_dims 來變換 shape\n",
    "\n",
    "這部分也可以用其他方法， 像是 numpy.reshape"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "single_inference_data = np.expand_dims(single_inference_data, axis=0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "再確認一下 shape"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "single_inference_data.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1, 59)"
      ]
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "丟入模型 inference, 就有結果了"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "single_predictions = model.run(single_inference_data) # predict!"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "這邊把全部測試資料丟入模型"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "source": [
    "predictions = model.run(test_data_array)# predict!"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "這邊 predictions 出來是 list, 把它轉成 np.array"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "source": [
    "type(predictions)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "metadata": {},
     "execution_count": 58
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "source": [
    "predictions = np.array(predictions)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "這邊轉完物件看一下 shape"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "source": [
    "predictions.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1, 12357, 1)"
      ]
     },
     "metadata": {},
     "execution_count": 60
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "這邊用 Numpy 裡面的 squeeze 降維以利後面進行資料處理\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "source": [
    "predictions = predictions.squeeze()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "source": [
    "predictions.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(12357,)"
      ]
     },
     "metadata": {},
     "execution_count": 56
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "資料分析的部份 code 跟之前在 SageMaker 上跑得一樣\n",
    "\n",
    "可以看到輸出結果跟之前在 SageMaker Notebook instance 上的一樣\n",
    "\n",
    "所以 model 有成功在本地端作用"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "source": [
    "cm = pd.crosstab(index=test_data['y_yes'], columns=np.round(predictions), rownames=['Observed'], colnames=['Predicted'])\n",
    "tn = cm.iloc[0,0]; fn = cm.iloc[1,0]; tp = cm.iloc[1,1]; fp = cm.iloc[0,1]; p = (tp+tn)/(tp+tn+fp+fn)*100\n",
    "print(\"\\n{0:<20}{1:<4.1f}%\\n\".format(\"Overall Classification Rate: \", p))\n",
    "print(\"{0:<15}{1:<15}{2:>8}\".format(\"Predicted\", \"No Purchase\", \"Purchase\"))\n",
    "print(\"Observed\")\n",
    "print(\"{0:<15}{1:<2.0f}% ({2:<}){3:>6.0f}% ({4:<})\".format(\"No Purchase\", tn/(tn+fn)*100,tn, fp/(tp+fp)*100, fp))\n",
    "print(\"{0:<16}{1:<1.0f}% ({2:<}){3:>7.0f}% ({4:<}) \\n\".format(\"Purchase\", fn/(tn+fn)*100,fn, tp/(tp+fp)*100, tp))\n",
    "\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Overall Classification Rate: 89.7%\n",
      "\n",
      "Predicted      No Purchase    Purchase\n",
      "Observed\n",
      "No Purchase    91% (10785)    34% (151)\n",
      "Purchase        9% (1124)     66% (297) \n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}